---
title: New Academy Grading Scheme
description: Research and proposal from Nuke
duration: 30 minuets
---

<!-- .slide: data-background-color="#4A2439" -->

# New Academy Grading Scheme

---

## 🤷 Motivations from Faculty

- Variability in educational standards/best practices for assignments & grading, leading to large subjectivity in scores awarded.
- Workload is very high for manual grading of 50 to 100 students with very tight deadlines.

---

## 🤷 Motivations from Students

- Rightly critical of totally opaque grading resulting only in a score with minimal written feedback
- Certification cutoffs leading to _anger and toxicity_ around the program and our ecosystem
- Over-focused on obtaining certification via assignments vs. excellence in their work

---

## 🎯 Goals

**Objective, easy to concretely define achievement, and concrete measures on assessment - qualitative and quantitative**

- Grading to be uniform and transparent for _everyone_
  - Test suites for code to _test_ functionality
- Maps _exactly_ with learning outcomes
- _Confine_ and make explicit where subjectivity of graders impacts scores
- Rubrics and complete _solutions_ for all graded material

Notes:

SME graders' subjectivity is still very important, topics like code quality, great use of patters/syntax, and "code beauty".
BTU we need to be confine that outside of hard skills & competencies in any assessments/scores/pass or fail
A "Perfect" example for the solution, and ideally various levels of score categories as example for each

---v

## 🎯 Goals

**Minimize faculty's time spent on grading _on-site_**

- Time on site is quite limited, interacting face-to-face is far more valuable than async reviewing and grading
- Minimize grading turn-around time to enable actionable feedback, iterations, and seeking support from SMEs
- (For now) the end of the in-person cohort defines absolute deadline for all grades

Notes:
We must balance between:

<pba-flex center>

1. Providing detailed feedback from SME to all students on all graded assignments
   - (At least option to request this, this can be TA's primary role)
1. Minimizing time and effort needed to assess work during a cohort

</pba-flex>

---v

## 🎯 Goals

**Student focus on growth & learning, not _only_ certification**

- [Learning, not earning! 📺](https://www.youtube.com/watch?v=CnSkOXe90WI)
- Foster intrinsic motivation & drive
- No points system can be high "rigor", focus must be on quality of work
- Encourages unique work & creative thinking
- Better granularity via skills and competencies, vs. "some number" that encompasses overall growth/accomplishment

---v

## 🎯 Goals

**Enable a pathway to thesis based model for multi-track future**

- Flexibility to break "out of the mold" to follow passions & dig deep
- More [latter in this deck](#pba-thesis-driven-certifications)

---v

## 🙅 Anti-goals

- "Shame" under-achievement that leads to exiting the ecosystem.
  - _We want to Maximize continued high-impact involvement post academy for all students and alumni_
- Normalization for the sake of specific percent not certifying
- "Gossip" and personal gripes/bias about students leading to bias & keep (by default, without good cause) _any_ subjective details on students out of the picture _between graders_.
  - _Thesis committee would break this rule, running after in-person cohort is complete_
- Unclear and subjective points systems with no clear definition that leads to grader interpretation of what a score means

---

<!-- .slide: data-background-color="#4A2439" -->

# Alternative Grading Frameworks

---v

## Alternative Grading Frameworks

- Overview: [📰 UC Berkeley Alternative Grading Frameworks](https://teaching.berkeley.edu/resources/course-design-guide/design-effective-assessments/alternative-grading-frameworks)
- Also [📰 University of Miami Alternative Grading Frameworks](https://academictechnologies.it.miami.edu/explore-technologies/technology-summaries/alternative-grading/index.html)
- There are many other interesting but even less common frameworks, not discussed in this presentation.

---v

## [📰 Grading for Equity](https://www.insidehighered.com/views/2020/01/27/advice-how-make-grading-more-equitable-opinion)

- Subjective criteria to minimum or zero
- Transparent scoring -> Are mathematically accurate to validly describe a student’s level of mastery
- No normalization
- Support hope and a growth mind-set
- “Lift the veil” on how to succeed

Notes:

- Transparent scoring -> Are mathematically accurate to validly describe a student’s level of mastery
  - They apply a more proportionately structured 0-4 scale instead of the 0-100 scale, which is mathematically oriented toward failure
  - They also use sound mathematical principles that reflect recent performance and growth instead of averaging performance over time
- Support hope and a growth mind-set
  - They allow test/project retakes to emphasize and reward learning rather than penalize it, and they override previous scores with current scores that build learning persistence
- “Lift the veil” on how to succeed
  - They create explicit descriptions of what constitutes demonstration of content mastery through rubrics or proficiency scales.
  - In addition, they simplify grade books and expand the methods of assessments to generate more accurate feedback and reporting about each student’s learning relative to the expected outcomes

---v

## [📰 Specs Grading](https://www.insidehighered.com/views/2016/01/19/new-ways-grade-more-effectively-essay)

- Pass fail only (like PRs!)
- Bundles to achieve levels

---v

## [📰 Ungrading](https://www.insidehighered.com/advice/2017/11/14/significant-learning-benefits-getting-rid-grades-essay)

- Reflection and Dialogue: Ungrading builds upon similar aspects of specifications and contract grading
  - Assignments provide clear instructions, although not necessarily criteria or contracts, for students to follow
  - Instructors should also offer students flexibility with assignment deadlines and provide opportunities for revision
  - Ungrading does encourage instructors to have more open conversations with students about their performance, whether it is through bi-weekly conferences, feedback surveys, or asking students outright what grade to put in the system at the end of the term (Blum & Kohn, 2020)
  - These conversations in addition to other self-reflective exercises (i.e. minute tickets, process letters, peer feedback, etc.) require students to think critically about what they’ve learned and articulate how they have developed their knowledge and skills throughout the semester

---v

## [📰 Contract Grading](https://en.wikipedia.org/wiki/Contract_grading)

- Collaboratively define grade qualifications with students (not completely pre-defined)
- Completion of a _contracted_ number of assignments of specified quality that correspond to specific letter grades
  - Instructors and students know exactly what is expected from them to receive a certain letter grade (no normalization)
  - Any student who completes the work that corresponds to a "B" grade will receive a "B" (everyone can pass)
- The grade the student receives is a reflection of how well they completed the pre-determined syllabus.

- _Variant: Labor-based contract grading = writing assessment be based on effort rather than on a subjective evaluation_

---v

## [Competency Grading 📺](https://www.youtube.com/watch?v=YQInjf8UjOo)

Great explainer in [three](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading) - [part](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading-2) - [serries](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading-3)

---

<!-- .slide: data-background-color="#4A2439" -->

# PBA's (proposed) Grading Scheme

---v

## PBA's (proposed) Grading Scheme

- Competency Checklist
- Scoring System
- Automated Grading Framework
- PR Reviews for Feedback
- Rubric and Solutions
- Certification Criteria

---v

## 🛂 Competency Checklist

Each assignment must define a set of **learning outcomes** in:

<pba-flex center>

1. Comprehension or Understanding
1. Skills or Abilities

</pba-flex>

Notes:

This is evaluated in a pass/fail manner, with grader feedback per item noted.

Some are explicitly defined to be optional-to-do items that if completed qualify for a higher level of grade.

---v

## 🛂 Competency Checklist

<img rounded src="img/competency-checklist.png" alt="competency-checklist" />

A "report card" of an assignment, <br>concatenated into one for the _entire academy_.

Notes:

Competencies are for the course overall, not just the assignment - there will be overlap between assignments.

---v

## 📊 Scoring System

**0 to 4 integer system, awarded per assignment**

- 0 = Nothing submitted or grossly poor performance
- 1 = Incomplete submission, under minimal requirements
- 2 = Passing all minimal requirements, pre-defined percent of test suite passing
- 3 = Passing all test suite items, including explicitly marked optional ones
- 4 = Grader discretion of going above the call of the assignment
  - Taking into account the level expected of students in context
  - Examples of what should qualify defined by creator(s)

---v

## 🤖 Automated Grading Framework

Based on Joshy's awesome work on the [📑 qualifying exam](https://github.com/Polkadot-Blockchain-Academy/Rust-Entrance-Exam) and [📑 assignment 0](https://github.com/Polkadot-Blockchain-Academy/pba-pre-course-assignment) we strongly suggest all (Rust based) assignments follow this standard:

<pba-flex center>

- Templated starting point with faculty to craft concrete assignments with `todo!("some things here...")` skeleton code defined
- Include "sanity check" and minimal unit tests that students _must_ complete
- Automated test suite (closed/private) to score granular pass/fail (based on learning objectives)

</pba-flex>

---v

## 🤖 Automated Grading Framework

Fully realized test suites will:

- Push creators to craft very well defined assessments
- Externalize _most_ effort to CI job for grading
- Enable resubmission by students anytime, iterating to passing

Notes:

Goal is to have "black box" that returns only pass/fail on tests, and a score of 1, 2, or 3.

---v

## 🧐 PR Reviews as Feedback

**Submissions include a README and/or PR comment**

- Points explicitly to what the SME should review
- Reflection on the work: key learning, things still to do, unresolved questions/issues the student had

---v

## 🧐 PR Reviews as Feedback

- Github Classrooms feedback PR can be used to comment directly on the work of each student easily
- An issue (template) opened on all classroom submission repos for manual grading
  - This is then the grading rubric and/or checklist for the grader to evaluate if the PR closes the issue.

---v

## 🧙 Rubric and Solutions

All assignments _must_ provide examples of end-to-end completed work to be included in grading, **for each possible score**

Notes:

For reference for faculty only for now, perhaps in a fully open course this should be open sourced.a

---v

## ✅ Certification Criteria

Options for criteria for certification:

<pba-flex center>

1. Average of integer scores for all assignments
1. Bundling of assignments that must be above a 2 to get cert
   - pre-defined
   - contract negotiated
1. Thesis Defense (only)

</pba-flex>

---

<!-- .slide: data-background-color="#4A2439" -->

# Assignment and Grading<br>Resources for Faculty

---v

## [📺 Developing Quality Assessments](https://www.youtube.com/watch?v=CnSkOXe90WI)

- Blooms taxonomy as basis with _explicit_ terms to use when defining learning objectives and outcomes
- WHY give this assignment? in context with content
- We assess on:
  - Process (thinking through) and/or product (shipped solution {code})
  - Express ideas concisely and coherently
  - Convergent (coming to conclusion based on given) or divergent (hypothesis from predictions & unstated things)

---

## [📺 Best Practices for Grading<br>Objectively and Efficiently](https://www.youtube.com/watch?v=hiUXBr4sgnM)

> Note that this is for typical grading systems (out of 100, A->F) that we will _not_ employ

---

<!-- .slide: data-background-color="#4A2439" -->

# PBA Thesis-driven Certifications

---v

## Thesis Driven Certification Integration

- Certifications granted at the closing ceremony are for _participation only_
- Post-cohort successful thesis defense lead to specific "proper" certifications/degrees (engineering, founder, etc.)

Notes:

The cert. exception may be the Application Engineers (parachain and solochain engineering) for completion of some level in all assignments.

---v

## Thesis Driven Certification Flow

PBA is already a "mini-masters" program, this would expand that analogy formally:

<pba-flex center>

1. Select Thesis Advisor
   - Student & advisor mutually agree on relationship
1. Thesis Proposal: defines work to be done, approved by Advisor (and retries if needed)
1. Thesis work: async support from Advisor
1. Thesis Committee: SMEs to evaluate thesis
1. Thesis Defense
1. Certification Awarded

</pba-flex>
