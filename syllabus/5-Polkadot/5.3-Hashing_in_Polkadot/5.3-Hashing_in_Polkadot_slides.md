---
title: M5:L3 The computational cost of hashing
description: Polkadot m5/l3
separator: "\r?\n---\r?\n"
verticalSeparator: "\r?\n---v\r?\n"
revealOptions:
  transition: "concave"
---


---

# The computational cost of hashing and how it drives polkadot design.

These slides are built with [reveal.js](https://revealjs.com/).

---

### Plan

---

### proof

Polkadot: Assessing that a parachain state transition is correct

Cumulus: parachains uses a trie state and cumulus define a given proof
No proof system assumed. In context of cumulus there is one.

Notes:
In practice design of system is currently and was historically largely
driven by the merkle trie state ethereum like design targetting.

---

### Merkle trie and proof

single value proof

TODO schema from the db & merklized slide

multiple value proof

TODO schema from the db & merklized slide

Notes:

this was alrealy evoked in length before. Just a reminder

Notice that there is no notion of order or sequence

---

### State transition proof

prove initial state and execute until same root as next block (through a stateless validation function)

Symetry of production (on a full state db) and verification (on a state proof)

Proofs do not help scaling, validators voting system does

Other system (eg zkrollup)

Notes:

we see that proof are just foot print of a state.
We are only really proving the start of block state and it is no
different than previous key values proofs.

scalability from polkadot design not the proof system

When creating proof we run on the state trie db, and record accesses.
TODO if time speak about cache and proofs

Polkadot design is ok for these proofs, what would not be fine
is verification being longer than production (would work but would make
parachain block size limit ridicously small in comparison to others.

can see the validator voting system as rather close to an interactive zk proof system.

Other Proofs
many are proposing very fast checking scalling the information level.
eg the eth zkrollup.

In this case the parachains geto a lot on his plate: heavy producing with 
lot of implication, quite challenging and all.
But putting this on parachain model is ok, just the light part would be runing
there: validator only check the zk proof.
So can think of it as a sub problem.

Merkle trie proofs are relatively simple to understand at a big cost though
but polkadot makes it acceptable

zkrollup could fit, just it is less interesting due to small cost of checking proof
(actually not true but that is a general opinion/idea)

---

### Proof size

Polkadot limit

Can grow big

Compact proof

zlib compression

Notes:

TODO find size limit

Be clear that the size is limited for transfer as storage.

Compact are good, even if it costs to run the hashes again we really favor smaller proof

zlib compress mainly the value included in the nodes, generally non deterministic: hard to measure.

As we will see after hashing here is not only a computational cost but a storage cost.

---

### Runtime update

runtime is in state

an extrinsic of the block is calling `set_code` through sudo

what happen?

Notes:

this value runtime is big... usual issues around the question
chunk solution...
Old runtime in proof?
-> TODO add a slide on the new trie format or just show how old one was not proper.

---

### Runtime storage design 

Balanced or Unbalanced trie

Runtime eg StorageMap

Custom eg `:code`

Module prefix

Child trie

Notes:

balancing trie always have been very important for security reason, deterministic weight calculation.
In ethereum for instance all key are hash of key. -> this way key length is constant and well distributed -> leading to a balanced trie

Though substrate runtime allows any length of key: meaning we can have unbalanced trie.

There is design concern: a smart contract will use as ethereum. :code will use this short key with few parent branch involve.
Modules will use some prefixing so they don't interfere with each other: if ballance module store a lot, and your nft storage does not, then the proof accessing nft only will not be impacted by the ballance module storage.

Child trie can be seen as prefix, but with their own root (very convenient to extract some state eg state of a given crowdloan/contract storage only).

---


### Reducing number of keys

Substrate value size is unbounded and can be rather large

polkadot will limit its size though

Less key by serializing values together

Depends on usage, always safe to keep value small

Notes:

if using all values usually then serializing them together is good.
using all values together or having a seldom read scenario: eg events
events are read a lot, but not from runtime. So write a single value containing
all events of a block.

Reduce proof size by requiring to include less parent branches.
Note state machine allows rather low cost update by having an `append` function.

if querying individual values, then storing individually is better:
higher write cost
accesses are done on individual values: individuals item.
Then please use different storage item, even in case of a list of item


A third consideration is clearly proof size: we want the PoV to be small: gaining a few branch is a good thing. But including big value in proof makes it worthless.

Conclusion do serialize values together, but carefully.
eg events are not read from runtime, but some proof, for light client notably may use a thiner storage (eg attaching event to a given extrinsic index).


Note earlier said polkadot limit size, but we could have write only value (eg event) that go over this size: by simple not being read.
Though all value should be unbounded, because in this scenario such big event value will become a liability when migrating (runtime could not migrate it easily as value is too big).

---

### Wrapping up

State impact:
- chains performance
- Proofs size

Different component similar design and consideration

Future: Changing storage (parachain or child trie)

TODOÂ diagram binary trie proof against hex proof showing binary is smaller
without too much thinking.

Notes:
chains performance:
				hex 16 makes is ok for 
proofs size
				bin proof better, higher computation


chain in synch: access a cache & on disk db.
btree in state machine
chain for block building: good state machine and cache big impact

cumulus: access in memory proof: overhead of loading it
also btree of state machine


today we only got hex16 child trie

using a binary child trie will reduce size of proofs for computation storage.

Bounded size child trie could also be interesting.

Things can really be custom

But not an easy task, cumulus really is a great tool.

generally as we see in case of polkadot there is a lot of freedom.


