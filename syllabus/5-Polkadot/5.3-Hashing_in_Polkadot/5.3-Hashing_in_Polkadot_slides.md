The computational cost of hashing and how it drives polkadot design.

# first slide a plan (all slide that would be see)

# proof

Polkadot: Assessing that a parachain state transition is correct.

Cumulus: parachains uses a trie state and cumulus define a given proof
No proof system assumed. In context of cumulus there is one.

Notes:
In practice design of system is currently and was historically largely
driven by the merkle trie state ethereum like design targetting.


# Merkle trie and proof

single value proof

TODO schema from the db & merklized slide

multiple value proof

TODO schema from the db & merklized slide

Notes:

this was alrealy evoked in length before. Just a reminder

Notice that there is no notion of order or sequence

# State transition proof

prove initial state and execute until same root as next block

Symetry of production and verification

Proofs do not help scaling, validators run them

Notes:

we see that proof are just foot print of a state.
We are only really proving the start of block state and it is no
different than previous key values proofs.

scalability from polkadot design not the proof system

When creating proof we run on the state trie db, and record accesses.
TODO if time speak about cache and proofs

Polkadot design is ok for these proofs, what would not be fine
is verification being longer than production (would work but would make
parachain block size limit ridicously small in comparison to others.


# zk proof

Asymetry


Notes:

many are proposing very fast checking scalling the information level.
eg the eth zkrollup.

In this case the parachains geto a lot on his plate: heavy producing with 
lot of implication, quite challenging and all.
But putting this on parachain model is ok, just the light part would be runing
there: validator only check the zk proof.
So can think of it as a sub problem.

Merkle trie proofs are relatively simple to understand at a big cost though
but polkadot makes it acceptable

zkrollup could fit, just it is less interesting due to small cost of checking proof
(actually not true but that is a general opinion/idea)

# Proof size

Polkadot limit

Can grow big

Compact proof

zlib compression

Notes:

TODO find size limit

Be clear that the size is limited for transfer as storage.

Compact are good, even if it costs to run the hashes again we really favor smaller proof

zlib compress mainly the value included in the nodes, generally non deterministic: hard to measure.

# Runtime update

runtime is in state

an extrinsic of the block is calling `set_code` through sudo

what happen?

Notes:

this value runtime is big... usual issues around the question
chunk solution...
Old runtime in proof?
-> TODO add a slide on the new trie format or just show how old one was not proper.








