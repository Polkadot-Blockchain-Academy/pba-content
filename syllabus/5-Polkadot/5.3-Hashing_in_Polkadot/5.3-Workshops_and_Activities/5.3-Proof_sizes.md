## Proof sizes

TODO consider proposing a rustling version of the jupyter note book with cells being test case:
jupyter is rather tricky to use:
- run on /tmp -> need clear manually sometime as there is compilation artifact.
- only the last cell can really be retried, otherwhise need to recompile from scratch.

Starting with a runtime module scaffold.

1. for each block use block number and writes 1 time `world` at key `hello`.

Look at proof size and compact proof size and proof after compression of 100 first blocks.

2. for each block use block number and writes `world` at key `hello ++ u32be of block_nb`.

Look at proof size and compact proof size and proof after compression of 100 first blocks.

3. merge both writes and execute 10 blocks

4. Get similar values  for {10, 100} block size chain and reading {1, 5, 10} random values from it.
These read proofs are what you get when reading from runtime or querying an rpc.

5. Compare result and see that they match expectation from lesson

## Quizz if time

TODO slides with individuals question


-> TODO rephrase so these looks more related to the lesson. + when saying state-machine point out it involves cumulus.


- State machine does cache changes, and can access state through some key value cache layer.
Considering that the key value cache layer is being shared between block execution (cache from block N-1 is accessible to block N as long as there was no reorg),
can I?

a - use cache for block synch
b - use cache for proof check
c - use cache for proof building
d - use cache for rpc

- State machine alows iterating on the underlying trie structure. What is true? [AI]

a - The api `next_key` is quite restrictive because it is easier to handle changed value.
b - The api `next_key` is quite restrictive because of host function design.
c - Caching is implemented there.
d - Involve additional cost for state machine.
e - Using a patricia merke trie is relevant.

- Merkle execution proofs size (eg merkle part of Pov) [A]

a - get bigger everytime we access state data.
b - get bigger for bigger values accessed
c - get bigger with a larger written values of a same written key.
d - get bigger with more written values of same length.
e - for a same value length can differ (eg querying different frame module)

- Proof verification model (cumulus/substrate pov case).

a - Block production and proof production can be done in a same execution.
b - Proof checking requires to fully execute the block.
c - Pvf wasm is the same as the parachain runtime.

- Execution model and state access/proof. [A]

a - While synching blocks, I use the proof.
b - While producing blocks, I use the proof.
c - While running pvf, I use the parachain state.
d - While running pvf, I use the parachain state root.
e - On a light client, I use the chain state.
f - On a light client, I use the chain state root.

- Previous question, but for any kind of proof system (%s/%r/I use /I can use /g).

- substrate trie is radix 16 while it could just be a binary radix 2 patricia trie.[I]

a - for the binary trie proof would be smaller
b - radix 16 makes bigger nodes which results in worse storage access. 


- child trie.

a - are similar to the hash of the node of a branch of an unbalanced trie
b - could potentially hold different kind of storage.
