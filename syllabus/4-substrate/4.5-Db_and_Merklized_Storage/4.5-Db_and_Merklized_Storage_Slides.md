Lecture 5, Module 4

Instructor: Shawn Tabrizi

---- 
# Database and Merklized Storage

In this section, we will learn about how the underlying storage layers in Substrate work and their behavior.

---

# Why is this topic important?

* To understand the main components of Substrate's storage system and how it serves the runtime.
* To make correct decisions when designing new runtime modules.

---

# Storage layers

### High level overview

There are core layers to Substrate's storage system.
```
  ┌────────────────────┐
  │Runtime Storage API │
  ├────────────────────┤
  │Overlay Change Set  │
  ├────────────────────┤
  │Patricia-Merkle Trie│
  ├────────────────────┤
  │Key-Value Database  │
  └────────────────────┘
```

TODO: Add proper diagram of storage layers

---
## Runtime Storage API

* `sp-io` can write to storage with a given key + value
* Substrate has macros that generate APIs to create different storage items as well as read/write to them

---
## Overlay Change Set

<div class="left">

* Stages changes to the underlying DB.
* Overlay changes are committed once per block.

</div>

<div class="right">

Two kinds of changes:

* Prospective Changes - what may happen.
* Committed Changes - what will happen.

</div>

Notes:

Should mention this is part of sp-state-machine

---

## Patricia-Merkle Trie

<div class="left">

* [paritytech/trie](https://github.com/paritytech/trie)
* Data structure on top of KVDB
* Arbitrary Key and Value length
* Nodes are Branches or Leaves

TODO: review this

</div>

<div class="right">

![Diagram of trie](http://placehold.jp/150x150.png)

</div>

---

## Key-Value Database (KVDB) Layer

<div class="left">

* Implemented with RocksDB and Parity DB
* Just KV mapping: `Blake2_256` Hash -> `Vec<u8>`

</div>

<div class="right">

| Key (Hash) | Value (`Vec<u8>`) |
| -----| --------| 
| 0x0fd923ca5e7 | [00] |
| 0x92cdf578c47 | [01] |
| 0x31237cdb79 | [02] |
| 0x581348337b | [03] |

Note: There could also be some in-memory KVDB layer for testing purposes.

Also in memory kvdb for proof checking.

---

### RocksDB

A Persistent Key-Value Store for Flash and RAM Storage.

* Keys and values are arbitrary byte arrays
* Fast
* Secure

Note:
See http://rocksdb.org/.
Big project, can be very tricky to configure properly. (also a big part of substrate compilation time).

---

### ParityDB

An Embedded Persistent Key-Value Store Optimized for Blockchain Applications.

* Designed for efficiently storing blockchain state encoded into a Patricia-Merkle trie
* Optimized write performance: "transactions"

Note:
"Transactions" here refers to "writes done in batches". 
In blockchains, writes are typically performed in large batches, when the new block is imported and must be done atomically.
See: https://github.com/paritytech/parity-db

TODO transaction are also part of rocksdb, the performance change here may be single writer (no concurrency on write). So this is relevant but not specific to rocskdb(should be moved in its own slide). Should be also noted that since we run a transaction per block (all in memory before), things are fast (that's probably what you meant).

The point for rocskdb I would mention is:
Key value indexed by default by hash, which makes access very fast but do not allow iteration.
With our merkle trie storage model, iteration on state value is done by the trie structure the having a kvdb with iteration support isn't needed.

Could mention 'Quick commit' : all changes are stored in memory and commit return fast , only writing in the WriteAheadLog in an asynchronous way.

Also simplicity in design (no cache (caching done by substrate)).

---

### Two Kinds of Keys

1. Trie key path 
2. KVDB key hash


Note:

A third kind could be the runtime storage access (module, storage structure and possibly key in strorage structure) (translate to trie key that then query kvdb hash). (I mention it because Runtime Api is in the high level overview).

---
## Cost to Read and Write

* Runtime -> overlay is cheap, etc.
* Where are the bottlenecks?
* Don’t have to pay the hashing or disk access

TODO: ???

Note:

Hashing cost is only when calculating the root (always end of block but can happen mid block if needed).

Generally the disk access cost is after block acceptance, it need to happen but is rather asynch.

---

## Database Backend

* Trie DB
* Trie Root 
* Storage Proofs

---

## Patricia-Merkle Trie

[Parity's Trie implementation](https://github.com/paritytech/trie) provides a generic implementation of the Base-16 Modified Merkle Tree datastructure.

<div class="left">

* Substrate uses a Base-16 Patricia Trie
* Merkle tree allows you to easily prove that some data exists within the tree with a “Merkle Proof”.

</div>

<div class="right">

![Merkle tree](/reveal-md/assets/4.5/merkle-tree-1.png)

TODO: update image design.

</div>

---
### Merkle tree 

<div class="left">

* Root node: can be used to verify two trees are the same.
* Branch nodes
* Leaf nodes

</div>

<div class="right">

![Merkle tree](/reveal-md/assets/4.5/merkle-tree-1.png)

TODO: update image design.

</div>

---

### Patricia trie 

<div class="left">

* Position in the tree defines the associated key.
* Space optimized for elements which share a prefix. 

</div>

<div class="right">

![Merkle tree](/reveal-md/assets/4.5/patricia-trie-1.png)

TODO: update image design.

</div>

---

* Patricia provides the trie path.
* Merkle provides the recursive hashing of children nodes into the parent.
* The Trie key path is set by you, for e.g. `:CODE`.
* A trie node has arbitrary length containing a header, key, possible children, possible value.
* KVDB key = Hash([Trie Node])

---

## Complexity

* Reading
* Writing 

---

## Reading

* O(log n) reads

![Merkle tree](/reveal-md/assets/4.5/complexity-storage-reads.png)

TODO: Update diagram with design.

---
## Writing

<div class="left">

* Very expensive for a database
* O(log n) reads, hashes and writes

1. Follow the trie path to the value.
    * O(log n) reads
2. Write the new value.
    * 1 write
3. Calculate new hash
    * 1 hash
4. Repeat (2) + (3) up the trie path
    * O(log n) times

</div>

<div class="right">

![Merkle tree](/reveal-md/assets/4.5/complexity-storage-reads.png)

</div>

TODO: Update diagram with design (modify accordingly)

---

## Merkle Proof

<div class="left">

* O(log n)
* Great for light clients!
* Low bandwidth, low computation

</div>

<div class="left">

1. Full Node: Follow the trie path to the value.
    * O(log n) reads
2. Full Node: Upload data of trie nodes.
3. Light Client: Download trie node data.
4. Light Client: Verify by hashing.
    * O(log n) hashes

</div>

Notes:

- Message is that proof is just enough trie content (can be a bag of node or some ordered node that needs to be complete with hashing as in compact proof TODO should we make a slide for compact proof and generally proof serialization?) to build a subset/subpart of the full state trie.

This incomplete trie will then be accessed and used identically as the full state trie, but if access is not part of the proof, then the action is not finishing: Proof Incomplete case.

Invalid proof are proof where the hashing don't match (can be see as multiple trie).

Can have some schema with the full state, then the proof and then two query on the proof: one that access data available and one that fail because incomplete (something that would work on 

- Another message to convey is that producing proof is really only recording all access made during some actions (key access, value insert, value change, trie iteration...).

This could be extended by the idea that key value caching should be disable for the first action otherwhise trie node would not be access and we would not register proof correctly.
-> can extend to basti pr where there is two kind of cache: trie node level cache that is safe to use and key value cache that 
Not sure it is worth going to far on cache strategy, but may be relevant to mention that by its structure trie node cache is shared between block.

- TODO a slide about keeping history of value: show that between two blocks trie nodes are shared and the storage structure of the trie inherently allow storing history of index.
-> I know there was one in Shawn deep dive presentation.
A final message to it should be that (eth see it), the storage model is still not the most efficient: we use merkle trie index to access node that are stored under a btree index (rocksdb), a true state db would have it's inner indexing directly using the merkle structure.
Paritydb in this sense in a good middle ground as it implement a hash map access directly so the merkle trie index is over a hash map rather than a btree map: that is a huge gain.

- another message to convey (I am not sure where) is that the trie structure (hexary) is mostly related to the storage model and do not produce the more compact proofs. One direction would be to decorelate storage from merklization. eg hexary node in storage but merklization over binary node. But the model get more complex. 

- Generally the message is also what works in memory as simple data structure, also work as a db over disk and also extend to being merklized. Usually things can be mapped or reffered to rather naturally. For instance an optimisation of radix trie is not storing the full merkle path in each node and get the key with the value: this work in memory (not a huge gain), this work on disk (huge gain as you can have fix len node which is big gain for disk access), can work with merkle proof (but tricky if codec still store the full partial key).


--- 

![Merkle tree](/reveal-md/assets/4.5/complexity-storage-reads.png)

TODO: Update diagram with design (modify accordingly)

---
## Exercise: discuss performance optimizations 

TODO: ask questions that relate to the work done here: https://github.com/paritytech/trie/pull/157 and https://github.com/paritytech/trie/pull/142 for students and lecturer to engage about optimizing state reads. Then look over the PR's motive.

---

## Overlay Deep dive

The overlay stages changes to the underlying database.

---

### Optimizations

* Minimize backend writes
* Minimize calculating storage root
* Only store consensus critical data in your runtime storage

---

### Balancing trie

- needed for contract
- not needed for runtime

Notes:

Here (or somewhere else) it must be evoked that trie path (key for values) are whatever the runtime want.
This is a very important design consideration:
in ethereum for instance everything is stored under hash(key), which makes the trie balanced amongst all value.
in substrate we allow random length key (there is a limit but very high in the trie impl), because the runtime
can be responsible of trie unbalance.
A slide showing an unbalance trie could be nice:
- a branch with module balance prefix and a lot of balance behind: making the query cost like 2 nodes for prefix and let's say 100_000 account so 16^5 -> ~ 5 nodes (accounts are hash and under the prefix things are balanced). -> 7 nodes to access
- a branch with some random 
odule and a constant in it : 2 nodes for prefix, + 2 nodes to access the constant. -> 4 nodes to access
- the wasm runtime at :code -> only 2 nodes

So choice of key (even if mainly made for you by the runtime storage macro) is very important.
And having an unbalance may sound like a bad thing, but it is not.

---

Substrate ships with additional ["transactional" overlays](https://github.com/paritytech/substrate/blob/master/frame/support/src/storage/transactional.rs).

This provides an API for developers to write logic with multiple storage writes in a single transaction, where:
* Either the entire changes to storage are committed..
* Or nothing is committed at all.

Note:
With this storage overlay, you don't need to verify each and every storage access before doing a modification.
In module 6, we can take a closer look at how this functionality is enforced for all FRAME extrinsics (see: https://github.com/paritytech/substrate/pull/11431).

---

## How does the Runtime sees state?

* `root()`, `get()`, `set()`, `next_key()`
* runtime sees state as a ordered Key-Value
* this Key-Value in the client is a Merkle tree

---

## Manual pruning exercise

Let's demonstrate what pruning looks like for retaining only the old Merkle Trie nodes.

---

## Workshop and Activity

* [Database and Merklized Storage Workshop](./4.5-Workshops_and_Activities/4.5-Db_and_Merklized_Storage_Workshop.md)
* [Database and Merklized Storage Activity](./4.5-Workshops_and_Activities/4.5-Db_and_Merklized_Storage_Activities.md)
