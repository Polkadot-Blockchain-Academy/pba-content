<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

  <title>Cryptography In Context</title>
  <link rel="icon" href="./../../assets/favicon.svg" />
  <link rel="shortcut icon" href="./../../assets/favicon.png" />
  <link rel="stylesheet" href="./../../dist/reset.css" />
  <link rel="stylesheet" href="./../../dist/reveal.css" />
  <link rel="stylesheet" href="./../.././assets/styles/PBA-theme.css" id="theme" />
  <link rel="stylesheet" href="./../../css/highlight/shades-of-purple.css" />

  <link rel="stylesheet" href="./../.././assets/styles/custom-classes.css" />

</head>

<body class="site">
  <header class="site-header">
    <!-- This logo is a link only on the watching server, not the production build -->
    <a href="">
      <img style="height: 2.5vw;" class="watermark-logo" src="./../../assets/img/0-Shared/logo/pba-logo-white.svg"
        alt="PBA Logo">
    </a>
  </header>
  <main class="reveal">
    <article class="slides">
      <section  data-markdown><script type="text/template">

# Cryptography in Context
</script></section><section  data-markdown><script type="text/template">
# Outline

<pba-flex center>

1. Keeping Secrets Secret
1. Security and Usability

</pba-flex>
</script></section><section  data-markdown><script type="text/template">
## Secrets

- What is a secret in cryptography?
- Data that you know, that nobody else knows.<!-- .element: class="fragment" data-fragment-index="2" -->
</script></section><section  data-markdown><script type="text/template">
## How Secrets Stay Secret

In order for a cryptographic secret to stay secret, the _only_ thing about it that can be revealed is the output of known, secured cryptographic operations.

- A (sufficiently random) secret can be hashed, and the hash revealed.<!-- .element: class="fragment" data-fragment-index="0" -->
- A private key can be used to generate a public key, and the public key revealed.<!-- .element: class="fragment" data-fragment-index="1" -->
- A private key can be used to generate a signature, and the signature revealed.<!-- .element: class="fragment" data-fragment-index="3" -->
</script></section><section  data-markdown><script type="text/template">
## How Secrets Get Leaked

1. Inadvertently leaking information about the secret during normal operation.<!-- .element: class="fragment" data-fragment-index="0" -->
1. Compromised digital or physical security leading to private key loss.<!-- .element: class="fragment" data-fragment-index="1" -->

<aside class="notes"><p>Let&#39;s go over each of these in order.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Bad Randomness

Some algorithms require randomness. If the randomness is compromised, the private key or encrypted message can possibly be exposed.

<aside class="notes"><p><a href="https://learn.saylor.org/mod/book/view.php?id=36341&amp;chapterid=18921">one source</a></p>
</aside></script></section><section  data-markdown><script type="text/template">
## Side Channel Attacks

A side channel attack is when a cryptographic system is attacked, and the attacker has another source of information outputted by the system.
</script></section><section  data-markdown><script type="text/template">
## Timing Attacks

A timing attack can be possible if any of the following<br/> depend on the contents of a secret:

<pba-flex center>

- Which instructions execute<!-- .element: class="fragment" data-fragment-index="0" -->
- Branching (if statements)<!-- .element: class="fragment" data-fragment-index="1" -->
- Memory access patterns<!-- .element: class="fragment" data-fragment-index="2" -->

</pba-flex>

<aside class="notes"><p>There are many crazy forms of side channel attack, but the primary one is timing. Timing is also the only one that gets reliably sent back over a long distance.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## An Example

Imagine this is the source code for a password checker:

```rust
fn verify_password(actual: &[u8], entered: &[u8]) -> bool {
 if actual.len() != entered.len() {
    return false;
 }

 for i in 0..actual.len() {
  if entered.get(i) != actual.get(i) {
   return false;
  }
 }
 true
}
```

What's the problem?

<aside class="notes"><p>Imagine you compile this into a little binary, and you are able to hit it repeatedly. When sending a guess into this, what information do you get back?</p>
<p>A boolean, and the amount of time from sending the password to getting back a response.</p>
<p>The problem is that the amount of time for a response reveals information about the password. An attacker can send in guesses repeatedly, and if it takes a longer amount of time to respond, that means more of the guess is correct.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Example (Cont)

What if we changed the code to look like this?

```rust
fn verify_password(actual: &[u8], entered: &[u8]) -> bool {
 actual == entered
}
```

Is this safe?

<aside class="notes"><p>Now, we don&#39;t see any difference in the amount of lines of code or loops, right?</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Example (Cont)

What does the source code look like?

```rust[0|1|7-9|15]
// Use memcmp for bytewise equality when the types allow
impl<A, B> SlicePartialEq<B> for [A]
where
    A: BytewiseEq<B>,
{
    fn equal(&self, other: &[B]) -> bool {
        if self.len() != other.len() {
            return false;
        }

        // SAFETY: `self` and `other` are references and are thus guaranteed to be valid.
        // The two slices have been checked to have the same size above.
        unsafe {
            let size = mem::size_of_val(self);
            memcmp(self.as_ptr() as *const u8, other.as_ptr() as *const u8, size) == 0
        }
    }
}
```

Is this safe?

<aside class="notes"><p>Ok, still no. It looks like now the attacker can still figure out if the length of the password based on an early return. But what if we make sure all passwords are 16 bytes long. Now we are just using a single syscall. Is is safe then?</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Example (Cont)

Let's check on `memcmp`.

```text
memcmp(3) â€” Linux manual page

/* snip */

NOTES
       Do not use memcmp() to compare security critical data, such as
       cryptographic secrets, because the required CPU time depends on
       the number of equal bytes.  Instead, a function that performs
       comparisons in constant time is required.  Some operating systems
       provide such a function (e.g., NetBSD's consttime_memequal()),
       but no such function is specified in POSIX.  On Linux, it may be
       necessary to implement such a function oneself.

```
</script></section><section  data-markdown><script type="text/template">
## So how could we do it?

This is from the `subtle` crate, which provides constant time equality.

```rust[0|14-15|20-28]
impl<T: ConstantTimeEq> ConstantTimeEq for [T] {
    /// Check whether two slices of `ConstantTimeEq` types are equal.
    ///
    /// # Note
    ///
    /// This function short-circuits if the lengths of the input slices
    /// are different.  Otherwise, it should execute in time independent
    /// of the slice contents.
    /* snip */
    #[inline]
    fn ct_eq(&self, _rhs: &[T]) -> Choice {
        let len = self.len();

        // Short-circuit on the *lengths* of the slices, not their
        // contents.
        if len != _rhs.len() {
            return Choice::from(0);
        }

        // This loop shouldn't be shortcircuitable, since the compiler
        // shouldn't be able to reason about the value of the `u8`
        // unwrapped from the `ct_eq` result.
        let mut x = 1u8;
        for (ai, bi) in self.iter().zip(_rhs.iter()) {
            x &= ai.ct_eq(bi).unwrap_u8();
        }

        x.into()
    }
}
```

<aside class="notes"><p>Now we&#39;ve seen how hard it can be just to stop a very simple leak of timing information. Let&#39;s see what an actual cryptographic library concerns itself with.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Ed25519's Guarantees

This is an excerpt from the [ed25519](https://ed25519.cr.yp.to/) description.

- **Foolproof session keys**. Signatures are generated deterministically; key generation consumes new randomness but new signatures do not. This is not only a speed feature but also a security feature.
- **Collision resilience**. Hash-function collisions do not break this system. This adds a layer of defense against the possibility of weakness in the selected hash function.
</script></section><section  data-markdown><script type="text/template">
## Ed25519's Guarantees (Cont.)

- **No secret array indices**. The software never reads or writes data from secret addresses in RAM; the pattern of addresses is completely predictable. The software is therefore immune to cache-timing attacks, hyperthreading attacks, and other side-channel attacks that rely on leakage of addresses through the CPU cache.
- **No secret branch conditions**. The software never performs conditional branches based on secret data; the pattern of jumps is completely predictable. The software is therefore immune to side-channel attacks that rely on leakage of information through the branch-prediction unit.
</script></section><section  data-markdown><script type="text/template">
## Takeway: DO NOT ROLL YOUR OWN CRYPTO

Preventing side channel attacks is _hard_! Noticing sidechannel attacks is even harder!

<img style="width: 800px;" src="./img/we_rolled_our_own_crypto.png" />

### 
<aside class="notes"><p>Be very, very careful whenever you do <em>anything</em> that touches a secret. That includes any operation involving the secret, or reading/writing it somewhere.</p>
<p>When necessary, talk to a security expert or cryptographer.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Using Cryptographic Libraries Safely

- Stay "above" the abstraction barrier<!-- .element: class="fragment" data-fragment-index="0" -->
- Validate each primitive's assumptions when combining primitives<!-- .element: class="fragment" data-fragment-index="1" -->
- Use the most reputable library you can<!-- .element: class="fragment" data-fragment-index="2" -->
- Realize when things need serious consideration<!-- .element: class="fragment" data-fragment-index="3" -->
- Some potentially scary terms: Curve point, padding schemes, IV, twisted curve, pairings, ElGamalb<!-- .element: class="fragment" data-fragment-index="4" -->

<aside class="notes"><p>Reputableness of a library is some combination of:</p>
<ul>
<li>used by many people</li>
<li>audited for security</li>
<li>reliable cryptographic literature</li>
<li>minimal external dependencies</li>
<li>recommended by cryptographers</li>
</ul>
<p>If you get low-level enough in cryptography libraries to see these terms referenced in more than just a description, you&#39;re probably too low level.</p>
</aside></script></section><section ><section data-markdown><script type="text/template">
# Horror Stories

<aside class="notes"><p>Only go through a few of these based on interest and remaining time.</p>
</aside></script></section><section data-markdown><script type="text/template">
## PS3 Secret Key Leak

**Problem**: Bad randomness

**Description**: The ps3 developers didn't use randomness when signing with an algorithm that required randomness.

**Consequence**: Every PS3 was hardcoded to trust that key. When hackers got the key, they were then able to pretend to be Sony and write any software that ran on the PS3. In practice, it made running pirated games trivial.

<aside class="notes"><p><a href="https://www.engadget.com/2010-12-29-hackers-obtain-ps3-private-cryptography-key-due-to-epic-programm.html">source</a></p>
</aside></script></section><section data-markdown><script type="text/template">
## IOTA's Novel Hash Function

**Problem**: Rolling your own crypto

**Description**: IOTA was a cryptocurrency with a value of 1.9B at the time. They wrote their own hash function, and researchers found severe vulnerabilities.

**Consequence**: Kind security researchers reported the flaw directly to devs. They had to pause the blockchain for 3 days, generate new address for _all_ accounts, and swap to KECCAK.

<aside class="notes"><p>IOTA originally rolled their own hash function in an effort to be quantum-proof.</p>
<p>Some hash function weaknesses are weak. This was not. The proof of concept exploit literally found two hashes that correspond to a message for the blockchain sending a small amount of currency, and another that corresponded to a message sending a huge amount of money.</p>
<p><a href="https://github.com/mit-dci/tangled-curl/blob/master/vuln-iota.md">exploit POC</a>
<a href="https://www.bitfinex.com/posts/215">shutdown source</a></p>
</aside></script></section><section data-markdown><script type="text/template">
## How the NSA wiretapped all cellphone calls for years

**Problem**: Small key space / secret technique

**Description**: The standard for cellphone calls up until the mid-late 2000s (GSM A5/1) used 54-bit keys, and the method was meant to be secret. It did not stay secret, and became extremely easily crackable.

**Consequence**: Intelligence agencies could and did easily wiretap calls. There were many brute-force attacks against the key space.

<aside class="notes"><p>When the standardization process started, professors proposed 128-bit keys. Western european (british especially) intelligence agencies wanted weaker security. Snowden eventually came out and said the NSA could easily read A5/1 calls.</p>
<p><a href="http://goodenoughsecurity.blogspot.com/2011/10/gsm-a51-substandard-security-pt2.html">article source</a>
<a href="https://www.aftenposten.no/verden/i/Olkl/sources-we-were-pressured-to-weaken-the-mobile-security-in-the-80s">source on weakening</a></p>
</aside></script></section><section data-markdown><script type="text/template">
## Why HTTPS isn't as secure as you'd hope

**Problem**: Cryptographic primitive assumptions not upheld

**Description**: Encryption _does not_ generally hide the length of the underlying message. HTTPS often uses compression before encryption. The compression makes duplicated strings smaller.

**Consequence**: An exploit called BREACH can reveal a secret from an HTTPS-protected website in under 30 seconds. All websites have had to add mitigation to offset this attack.

<aside class="notes"><p>Mitigation looks like:</p>
<ul>
<li>randomizing size of response content after compression</li>
<li>separating secrest from user input</li>
<li>disabling HTTP compression (this is expensive though)</li>
<li>randomizing secrets per request</li>
</ul>
<p><a href="https://arstechnica.com/information-technology/2013/08/gone-in-30-seconds-new-attack-plucks-secrets-from-https-protected-pages/">source</a></p>
</aside></script></section></section><section  data-markdown><script type="text/template">
## Physical Security

<img style="width: 900px;" src="./img/xkcd-physical-security.png" />

<aside class="notes"><p>Source is a classic XKCD comic.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Physical Security

Full physical access to a running computer can usually let an attacker have full access to your secrets with enough effort.

Some possible means:

- Scanning all disk storage
- Take out the RAM and swap it into a different computer to read (cold boot attack)
- Proximate side-channel attacks
  - RF emissions
  - Power consumption
  - Sound of a computer running

<aside class="notes"><p>Sources for exotic attacks:</p>
<ul>
<li><a href="https://arxiv.org/abs/1903.07703">general survey of EM side channel attacks</a></li>
<li><a href="https://www.iacr.org/archive/crypto2014/86160149/86160149.pdf">sound-based attack</a></li>
<li><a href="https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1648290&amp;dswid=6646">EM side channel attack from 15m with 500 traces only</a></li>
</ul>
</aside></script></section><section  data-markdown><script type="text/template">
## HSMs

An HSM is a **h**ardware **s**ecurity **m**odule. HSMs can make it much harder to impossible to steal cryptographic keys. An HSM will hold cryptographic keys, and perform operations on them.

<aside class="notes"><p>We don&#39;t go into this much, as there are many available resources around physical security and HSMs. This is just bringing up the ideas, in the context of what makes a cryptographic secret actually <em>secret</em>.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Security and Usability

The accessibility of a secret is typically inversely proportional to the security.

Making a secret more secure is often impractical, depending on the usage.

<aside class="notes"><p>This is not explicitly true in all cases, but it is a good rule of thumb. Additionally, note that impractical != impossible.</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret, I'll give you a million dollars.

What do you do?
</script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret, I'll give you a million dollars.

What do you do?

### Destroy it
</script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret **and you present me the secret**, I'll give you a million dollars.

What do you do?
</script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret **and you present me the secret**, I'll give you a million dollars.

What do you do?

### Hide it somewhere secure

<aside class="notes"><p>Like a bank vault, box buried in the woods, etc</p>
</aside></script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret **and you present me the secret once per month**, I'll give you a million dollars.

What do you do?
</script></section><section  data-markdown><script type="text/template">
## Thought Experiment

Suppose I give you a secret that's too long to memorize.

At the end of a year, if nobody else knows the secret **and you present me the secret every day**, I'll give you a million dollars.

What do you do?
</script></section><section  data-markdown><script type="text/template">
## Application to Cryptographic Secrets

Cryptographic secrets are easy to have multiple of.

So don't make users use the same one for everything!

As much as possible, one root secret shouldn't be _both_ used regularly, and extremely valuable.
</script></section><section  data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# Questions
</script></section>
    </article>
  </main>

  <script src="./../../dist/reveal.js"></script>

  <script src="./../../plugin/markdown/markdown.js"></script>
  <script src="./../../plugin/highlight/highlight.js"></script>
  <script src="./../../plugin/zoom/zoom.js"></script>
  <script src="./../../plugin/notes/notes.js"></script>
  <script src="./../../plugin/math/math.js"></script>

  <script src="./../../assets/plugin/mermaid.js"></script>
  <script src="./../../assets/plugin/mermaid-theme.js"></script>

  <script src="./../../assets/plugin/chart/chart.js"></script>
  <script src="./../../assets/plugin/chart/chart.min.js"></script>

  <script src="./../../assets/plugin/tailwindcss.min.js"></script>

  <script>
    function extend() {
      var target = {};
      for (var i = 0; i < arguments.length; i++) {
        var source = arguments[i];
        for (var key in source) {
          if (source.hasOwnProperty(key)) {
            target[key] = source[key];
          }
        }
      }
      return target;
    }

    // default options to init reveal.js
    var defaultOptions = {
      controls: true,
      progress: true,
      history: true,
      center: true,
      transition: 'default', // none/fade/slide/convex/concave/zoom
      slideNumber: true,
      mermaid: {
        startOnLoad: false,
        logLevel: 3,
        theme: 'base',
        themeVariables: {
          primaryColor: purple,
          primaryTextColor: white,
          primaryBorderColor: pink,
          lineColor: pink,
          secondaryColor: lightPurple,
          tertiaryColor: lightPurple,
        },
      },
      chart: {
        defaults: {
          color: 'lightgray', // color of labels
          scale: {
            beginAtZero: true,
            ticks: { stepSize: 1 },
            grid: { color: "lightgray" }, // color of grid lines
          },
        },
        line: { borderColor: ["#ccc", "#E6007A", "#6D3AEE"], "borderDash": [[5, 10], [0, 0]] },
        bar: { backgroundColor: ["#ccc", "#E6007A", "#6D3AEE"] },
      },
      plugins: [
        RevealMarkdown,
        RevealHighlight,
        RevealZoom,
        RevealNotes,
        RevealMath,
        RevealMermaid,
        RevealChart
      ]
    };

    // options from URL query string
    var queryOptions = Reveal().getQueryHash() || {};

    var options = extend(defaultOptions, {"width":1400,"height":900,"margin":0,"minScale":0.2,"maxScale":2,"transition":"none","controls":true,"progress":true,"center":true,"slideNumber":true,"backgroundTransition":"fade"}, queryOptions);
  </script>


  <script>
    Reveal.initialize(options);
  </script>
</body>

</html>
