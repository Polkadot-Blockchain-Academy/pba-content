---
title: Game Theory Basics
description: Game Theory Basics for Web3 engineers
duration: 1 hour
instructors: ["some one", "another gal"]
teaching-assistants: ["some one", "another gal"]
slideOptions:
  # transition: 'fade'
  # parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'
---

<style>
.reveal p {
  font-size: 24px;
  text-align: left;
}
.reveal {
  font-size: 24px;
  text-align: left;
}

.aligncenter {
    text-align: center;
}
</style>

# Lesson 2 -- Game Theory Basics (60 min)

---

# 1. Introduction

---

> Game theory is the study of mathematical models of conflict and cooperation between intelligent and rational decision makers. Rational means that each individual’s decision-making behavior is consistent with the maximization of subjective expected utility. Intelligent means that each individual understands everything about the structure of the situation, including the fact that others are intelligent rational decision makers. (Roger Myerson, 1986)

---

* Early “game theoretic” research that still resonates today goes way back into the early 19th century:
    * 1838, Antoine Augustin Cournot: Cournot competition, uses an early, simplified version of Nash equilibrium.
    * 1881: Francis Edgeworth: trade with two consumers and two goods. 
    * 1913, Ernst Zermelo: chess, first formal application of backward induction.

---

* The systematic study of games started in the 40/50s of the 20th century:
    * 1944: John von Neumann and Oscar Morgenstern publish *Theory of Games and Economic Behavior*.
    * 1949: John Nash writes his dissertation. His best known contribution  is on the general existence of a solution (the Nash equilibrium) for the important class of finite games.
    * 1963: Douglas Gale and Lloyd Shapley publish seminal work on matching.
    * 1973: John Harsanyi provides important insights into mixed strategies.
    * 1976: Robert Aumann publishes seminal work on common knowledge of rationality.

---

* Today, game theory is widely used not only in economics, but also in biology, sociology, political science, psychology, among others.
* In economics, game theory is used to analyze many different strategic situations. Examples include
    * Auctions.
    * Industrial economics.
    * Business administration.
* In the context of blockchains, game theoretic reasoning is often used for:
    * Tokenomics: The specific design of how people interact in the ecosystem.
    * Consensus: Is following the consensus rules indeed incentive compatible?

---

* Game theory is *abstract*:
    * Game theoretic models aim to get at the essence of a given strategic problem. This often requires that many facets of the problem are assumed away.
    * Pro: Abstraction makes the problem amenable to analysis and helps to identify the key incentives at work.
    * Con: (A certain) lack of realism.

---

# 2. What is a Game?

---

A game is a strategic interaction between several players, where ...
1. ... all the possible *actions* of the players,
2. ... all the possible *outcomes*, and
3. ... how each combination of actions affects which outcome will realize ...

... are *common knowledge* among all the players of the game.

---

**Definition: Common Knowledge**

An event $X$ is common knowledge if if (1) everyone knows $X$, (2) everyone knows that everyone knows $X$, (3) everyone knows that everyone knows that everyone knows $X$, and so on ad infintum.

---

* Examples:
    * Auctions:
        * Actions: Bids.
        * Outcome: Winner and Payment.
    * Price-competition between firms:
        * Actions: Price charged.
        * Outcome: Demand for each firm, profit of each firm.
* Crucial feature of a game: outcome not only depends on own actions but also on the actions of the other players.

---

Traditionally, game theory distinguishes between

* static and dynamic games, as well as
* games of complete information and games of incomplete information.

---

| Static Game | Dynamic Game |
|---|---|
| All players take their actions at the same time | Players move sequentially and possibly multiple times, (at least partially) observing previous actions |
| Example: Sealed-bid auction. All bidders submit their bids simultaneously (resp. in a sealed envelope). No player knows what others bid. | Example: English auction. Auctioneer publicly raises price as long as at least one bidder accepts the price. |

---

| Game of Complete Information | Game of Incomplete Information |
|---|---|
| Preferences of the players are common knowledge. | Preferences are not common knowledge. |
| Example: Competition between firms (assuming that all firms know other firms' costs). | Example: Most art auctions. People tend to have higly subjective preferences that they only know themselves. |

---

* This lecture focuses on static games of complete information.
* When we look at auctions in Session 3.3, we will also consider games of incomplete information, both dynamic and static.

---

# 3. Two well-known static games of complete information

---

## 3.1 Prisoners' Dilemma



* Bonnie and Clyde are accused of robbing two banks. 
    * The evidence for the first robbery is overwhelming and will certainly lead to a conviction with two years of jail.
    * The evidence for the second robbery is not sufficient and the two will only be be convicted for that robbery in case of a confession by either or both.

---

* Bonnie and Clyde are interrogated in two different rooms, and both are offered the following:
    * If you both confess you will both go to jail for four years.
    * If you do not confess while your partner does, you will go to jail for five years (one additional year for obstruction of justice).
    * However, if you confess but your partner does not, then we reduce your jail time to one year.

---

* Bonnie and Clyde can either cooperate (denoted by: C) and not tell anything, or they can defect (D) and confess their crime.
 
![](https://i.imgur.com/ypcgb47.png)

---

* Consider Bonnie: 
    * If Clyde chooses C, she optimally chooses D.
    * If Clyde chooses D, she optimally chooses D.
* Choosing D is a *dominant strategy*: no matter what Clyde does, it is always the best choice.

![](https://i.imgur.com/oz2UuyT.png)

---

* The same holds true for Clyde.
* So, they end up both defecting, resulting in 4 years each.

![](https://i.imgur.com/T5aySON.png)

---

* It would be in their best interest to cooperate.
* However, both Bonnie and Clyde are rational utility maximizers.
* So, they end up in a Pareto-inferior outcome.

---

* Main finding: Cooperation is not feasible even though pareto-superior.
* Real-life examples: 
    * NATO and Russia in their arms race: Both prefer no arms race to an arms race. Yet, having some arms is preferrable to having no arms, irrespective whether to other one is armed.
    * OPEC / Cartels more general: Limiting oil supply is in the best interest of all. However, given the high price that thus results, everyone has an inentive to increase individual oil supply to maximize profits.


---

* OPEC seems to overcome the Prisoners' Dilemma.
* How to overcome the no-cooperation outcome in Prisoners' Dilemmas?
* Repeated Prisoners' Dilemmas!
* Famous result: If Prisoner's Dilemma is infinitely repeated then it is an equilibrium for both to cooperate (provided they are sufficiently patient).


---

## 3.2 Coordination Game

* Predictions are not always so clear.
* Consider the following coordination game with two players. 
* The numbers represent the payoffs a player receives. We assume that more is better.

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0usf{background-color:#000000;border-color:#ffffff;color:#ffffff;text-align:center;vertical-align:top}
.tg .tg-icqp{background-color:#000000;border-color:#333333;color:#ffffff;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-0usf"></th>
    <th class="tg-0usf"></th>
    <th class="tg-0usf" colspan="2">Player 2</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0usf"></td>
    <td class="tg-icqp"></td>
    <td class="tg-icqp">L</td>
    <td class="tg-icqp">R</td>
  </tr>
  <tr>
    <td class="tg-0usf" rowspan="2">Player 1</td>
    <td class="tg-icqp">L</td>
    <td class="tg-icqp">1,1</td>
    <td class="tg-icqp">0,0</td>
  </tr>
  <tr>
    <td class="tg-icqp">R</td>
    <td class="tg-icqp">0,0</td>
    <td class="tg-icqp">1,1</td>
  </tr>
</tbody>
</table>

---

* The players only obtain utility if they coordinate their actions.
* Examples:
    * Driving on the right/left side of the road.
    * Money adoption.
    * Standard adoption.


---

* The coordination game has two outcomes (L,L) and (R,R) that are stable in the following sense: 
    * if both players choose it, then neither player wants to *unilaterally* deviate from her choice.
* Both are instances of *Nash equilibrium*. 
* **Definition: Nash Equilibrium**. A combination of actions such that all players choose optimally *given* the actions of the other players.
* Coordination games always have multiple equilibria.

---

* So which outcome does the theory of Nash equilibrium predict?
* Answer: neiter. 
* Also, sometimes people switch between equilibria (if they are made to)...

![](https://i.imgur.com/fJvBBsg.jpg)
Sweden, 1967.

---

## 3.3 Schelling Points

* While the theory of Nash equilibrium does not provide a clear prediction of play in the coordination game, other theories sometimes do.
* A prominent one is the theory of so-called *Schelling points*.
* A Schelling point (aka focal point) is a solution that people tend to choose by default in the absence of communication. 
* The concept was introduced by the American economist Thomas Schelling in his book The Strategy of Conflict (1960).

---

* Schelling ran a couple of informal experiments in which he asked his students: 
> If you are to meet a stranger in New York City, but you cannot communicate with the person, then when and where will you choose to meet? 
* This is a coordination game. Literally *any* point and time is a Nash equilibrium. 
* However, most people responded: noon at (the information booth at) Grand Central Terminal.
* Basic idea: in case of multiple equilibria, social norms may help to choose one.

---

# 4. Some Other Relevant Games

---

## 4.1 Public-Good Game

* What is a public good?
    * Non-rivalrous
    * Non-excluding
    
* Examples:
    * Fireworks
    * A public park
    * The coffee machine in the office
    * Polkadot's Public Good Parachains
* Let's model the basic concepts in a game.

---

* Consider a game with three players.
* All players have some endowment, e.g., 10 Points.
* Each player can choose how much to contribute to the public good.
* The sum of all contributions is multiplied by $\alpha = 0.6$ and paid out to the all players.
    * The value of the public good increases with the amount of contributions.
    * Every player (regardless of the contribution) is allowed to consume the public good.

---

* Each player $i$ contributes an amount $c_i \in [0,10]$.
* The payoff function of each player is 
$$10 - c_i + \alpha  \sum_{j=1}^{n} c_j.$$ 


---

* How would you interpret $\alpha$ ?
* How would you interpret $n*\alpha$?
* What would be the best for the collective?

Notes:
* $\alpha$ is the private marginal benefit.
* $n*\alpha$ is the social marginal benefit.

---

* The optimum for the collective maximizes total welfare, 

$$10 n - \sum_{j=1}^n c_j + n\alpha \sum_{j=1}^n c_j = 10n - (1-n\alpha)\sum_{j=1}^n c_j.$$

* Clearly, if $n\alpha > 1$, then it is socially optimal if everyone contributes, $c_i = 10$.
* Observe: $n\alpha>1$ means that the marginal social benefit of the joint conributions is higher than the marginal costs of the contributions.

---

* Is the socially optimal behavior an individually optimal strategy here?
    * No. We have $\alpha<1$. 
    * So, the individual payoff is always maximized when not contributing at all.
* Observe: Not contribution is a dominant strategy.
* So, our public good game is a prisoner's dilemma with more than two players.

---

What about empirical evidence?
* What do you think happens when playing this with real humans...
    * ... for one round?
    * ... for many rounds?
    * ... when allowing for communication?
    * ... with different sizes of the groups?

Notes: 
* No contribution when played for one round.
* Some little contribution but quickly to 0.
* Some longer and stronger contribution but eventually going to 0 quickly
* The more people the higher the perceived possibility to free ride.

---

* Polkadot solves the underprovision of a public good with a subsidy
    * Parachains that offer functionality / utility to all users but struggle to find a business case can receive a slot for free.
    

---

## 4.2 Tragedy of the Commons

* Tragedy of the commons is related to public good provision.
* We study a very similar model with a slightly different utility function.

---

* Two players, a resource K, either enjoys consuming $k_i$ but both also enjoy the remaining resource $K-k_1-k_2$.
* Utility of player $1$: $u_1(k_1,k_2) = \ln(k_1)+\ln(K-k_1-k_2).$ 
* Utility of player $2$: $u_2(k_1,k_2) = \ln(k_2)+\ln(K-k_1-k_2).$

---

* Each player derives utility from own consumption, but gets hurt by the consumption of the other player.
* Examples:
    * (Over-)Fishing: Fishing gives private benefit but might destroy broader ecosystem, which has its own value for everyone (due to, e.g., tourism).
    * Air pollution: Producing a good yields private profit but reduces air quality for everyone.
    * Bitcoin: Mining gives private benefit in the form of mining rewards but hampers environment for everyone.

---

* Nash equilibrium: $(k_1^*,k_2^*)$ such that $k_1^*$ is optimal given $k_2^*$ and vice versa. 
* Fix consumption of player $2$, $k_2$, and find player $1$'s best response $BR_1(k_2)$.

$$\frac{\partial u_1(k_1,k_2)}{\partial k_1} = 0 \iff \frac{1}{k_1} =\frac{1}{K-k_1-k_2} \iff k_1 = \frac{1}{2}[K-k_2] \equiv BR_1(k_2).$$

* Fix consumption of player $1$, $k_1$, and find player $2$'s best response $BR_2(k_1)$.

$$\frac{\partial u_2(k_1,k_2)}{\partial k_2} = 0 \iff \frac{1}{k_2} =\frac{1}{K-k_1-k_2} \iff k_2 = \frac{1}{2}[K-k_1] \equiv BR_2(k_1).$$

---

* Nash equilibrium $(k_1^*,k_2^*)$ consists of mutual best responses,

\begin{align}
k_1^* &= BR_1(k_2^*) \\
k_2^* &= BR_2(k_1^*)
\end{align}

* Solution: $k_1^*=k_2^*= K/3.$

---

* What is the tragedy here? Players consume more than the socially optimal amount.
* Socially optimal: maximize total welfare $W(k_1,k_2)=u_1(k_1,k_2)+u_2(k_1,k_2)$.
* Optimality conditions

\begin{align}
\frac{\partial W(k_1,k_2)}{\partial k_1} = 0 &\iff \frac{1}{k_1} =\frac{2}{K-k_1-k_2} \iff k_1 = \frac{1}{3}[K-k_2] \\
\frac{\partial W(k_1,k_2)}{\partial k_2} = 0 &\iff \frac{1}{k_2} =\frac{2}{K-k_1-k_2} \iff k_1 = \frac{1}{3}[K-k_2]
\end{align}

---

* Solution: $\hat k_1 = \hat k_2 = K/4$.
* The socially optimal consumption level is *lower* than the mutually optimal one.
* Why? Consumption externality: each player inflicts harm on the other player when consuming but does not take this into account for the individually optimal decision.
* What about utilities?

\begin{align}
u_1(k_1^*,k_2^*) &= \ln(K/3)+\ln(K/3) = \ln(K^2/9) \\
u_1(\hat k_1,\hat k_2) &= \ln(K/4) + \ln(K/2) = \ln(K^2/8) 
\end{align}

* Both players would be better off in the social optimum.

---

* Traditional solutions: 
    * taxes.
    * licenses.

  
---

# Classroom Discussions (30 min)

---

## Classroom Discussion 1: Public-good parachains. 

* Polkadot has the idea of public-good parachains.
* Discuss reasons for why we have this in the first place.

---

## Classroom Discussion 2: Consensus as public good (leave this out bc. blockchains come later?).

* Discuss in what sense consensus is a public good.
* What is the problem of mixed equilibrium for consensus?
* Discuss asymmetric equilibria.

---

## Classroom Discussion 3: Prisoner's Dilemma?

* Read this article: https://bitcoinmagazine.com/culture/the-bitcoin-dilemma.
* Discuss why the "Bitcoin Dilemma" is probably not a Prisoner's' Dilemma (as claimed).

Notes:
* Why the task?
    * It reinforces the concepts of cooperative and non-cooperative games as well as concepts of complete and incomplete information (does it? Or do we need to make it more explicit).
    * It reinforces the concept of the prisonner's dilemma
    * It challenges students to apply their knowledge to the blockchain space.



---

# Workshop (70 min)

---

* The plan is to let the students play a couple of class-room experiments to earn points for the auction in the next lesson.
* P-beauty contest
    * Illustrate level-k thinking
    * Results mostly not in the NE
    * Importantly: Playing NE does not yield a chance to win
* Repeated Prisoners Dilemma (with chat)
* Public good game with punishment
* We will use o-tree and implement the process and resources as outlined here: https://hackmd.io/xDzK30yjTuG2CxccrFZBuw

