<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

  <title>Graded Assignments Scheme</title>
  <link rel="shortcut icon" href="./../assets/favicon.ico" />
  <link rel="stylesheet" href="./../dist/reset.css" />
  <link rel="stylesheet" href="./../dist/reveal.css" />
  <link rel="stylesheet" href="./../assets/styles/PBA-theme.css" id="theme" />
  <link rel="stylesheet" href="./../css/highlight/shades-of-purple.css" />

  <link rel="stylesheet" href="./.././assets/styles/custom-classes.css" />

</head>

<body class="site">
  <header class="site-header">
    <!-- This logo is a link only on the watching server, not the production build -->
    <a href="">
      <img style="height: 2.5vw;" class="watermark-logo" src="./../assets/img/0-Shared/logo/pba-logo-white.svg"
        alt="PBA Logo">
    </a>
  </header>
  <main class="reveal">
    <article class="slides">
      <section ><section data-markdown><script type="text/template">

<!-- .slide: data-background-color="#F35289" -->

<h1 style="color:#FFFF;"> ⏰ TODOs before Berkeley ⏰ </h1>
</script></section><section data-markdown><script type="text/template">
## 🗣️ Dry Runs (Lectures)

- New faculty (required!)
- New and Major refactored content (required!)

<aside class="notes"><p>Anyone still need this? We have VERY little time!</p>
</aside></script></section><section data-markdown><script type="text/template">
## 💻 Beta Testing (Hands-on/Code)

- New Material
- Assignments

<aside class="notes"><p>Anyone still need this? We have VERY little time!</p>
</aside></script></section><section data-markdown><script type="text/template">
## 📆 Founders Track Lessons required

- Flag what is applicable for Founders track in module README

<aside class="notes"><ul>
<li>founders track pilot program (30% of class, branching off 1/3 of day starting in the smart contracts module)<ul>
<li>working with daily play-by-play on core content, but need to identify what founders will get most value from: the non-hands-on stuff and concepts most of all past the SC mod</li>
<li>internal calendar of events getting close to final draft, will go student and faculty facing ASAP</li>
</ul>
</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">
## 🤙 1on1 checking pre-UCB

- Modules to meet with Nuke to cover their [key milestones](https://hackmd.io/aE6i_ZQpSwaOSfHVpApOcg?both)
</script></section><section data-markdown><script type="text/template">
## 🙌 Assignment Grading Plan

- Rubrics and solutions (required!)
- Who owns grading?
  - VERY tight turnaround (Start Sunday, ideally done Monday)
</script></section><section data-markdown><script type="text/template">
## ✅ Create Learning Outcomes

1. Update your module `lesson-plan.md` with LOs
1. Map overall LOs to define assignment specific LOs in README
1. Map assignment LOs to Competency Checklist
1. _Granular list of tests per checklist item that (a fraction of) must pass_

- Scope mapping LOs->tests for now in an issue, impl autograding where possible soon

<aside class="notes"><p>Tests are not mission-critical, but the checklists are to generate a score.
Defining the tests lays the foundation for autograding.
WIP <a href="https://github.com/Polkadot-Blockchain-Academy/pba-autograded-assigment-template">assignment template</a> we can work together to put in place for each assignment when it&#39;s ready</p>
</aside></script></section></section><section ><section data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# Graded Assignments Scheme
</script></section><section data-markdown><script type="text/template">
## 🤷 Motivations from Faculty

- Variability in educational standards/best practices for assignments & grading, leading to large subjectivity in scores awarded.
- Workload is high for manual grading of 50 to 100 students with _very_ tight deadlines.

<aside class="notes"><p>Based on lessons learned in the first two cohorts about assessment.</p>
</aside></script></section><section data-markdown><script type="text/template">
## 🤷 Motivations from Students

- Rightly critical of totally opaque grading resulting only in a score with minimal written feedback
- Certification cutoffs leading to _anger and toxicity_ around the program and our ecosystem
- Over-focused on obtaining certification via assignments vs. excellence in their work
</script></section><section data-markdown><script type="text/template">
## 🎯 Goals

**Objective, easy to concretely define achievement, and concrete measures on assessment - qualitative and quantitative**

- Grading to be uniform and transparent for _everyone_
  - Test suites for code to _test_ functionality
- Maps _exactly_ with learning outcomes
- _Confine_ and make explicit where subjectivity of graders impacts scores
- Rubrics and complete _solutions_ for all graded material

<aside class="notes"><p>SME graders&#39; subjectivity is still very important, topics like code quality, great use of patters/syntax, and &quot;code beauty&quot;.
BTU we need to be confine that outside of hard skills &amp; competencies in any assessments/scores/pass or fail
A &quot;Perfect&quot; example for the solution, and ideally various levels of score categories as example for each</p>
</aside></script></section><section data-markdown><script type="text/template">
## 🎯 Goals

**Minimize faculty's time spent on grading _on-site_**

- Time on site is quite limited, interacting face-to-face is far more valuable than async reviewing and grading
- Minimize grading turn-around time to enable actionable feedback, iterations, and seeking support from SMEs
- (For now) the end of the in-person cohort defines absolute deadline for all grades

<aside class="notes"><p>We must balance between:</p>
<pba-flex center>

<ol>
<li>Providing detailed feedback from SME to all students on all graded assignments<ul>
<li>(At least option to request this, this can be TA&#39;s primary role)</li>
</ul>
</li>
<li>Minimizing time and effort needed to assess work during a cohort</li>
</ol>
</pba-flex></aside></script></section><section data-markdown><script type="text/template">
## 🎯 Goals

**Student focus on growth & learning, not _only_ certification**

- [Learning, not earning! 📺](https://www.youtube.com/watch?v=CnSkOXe90WI)
- Foster intrinsic motivation & drive
- No points system can be high "rigor", focus must be on quality of work
- Encourages unique work & creative thinking
- Better granularity via skills and competencies, vs. "some number" that encompasses overall growth/accomplishment
</script></section><section data-markdown><script type="text/template">
## 🎯 Goals

**Enable a pathway to thesis based model for multi-track future**

- Flexibility to break "out of the mold" to follow passions & dig deep
- More [latter in this deck](#pba-thesis-driven-certifications)
</script></section><section data-markdown><script type="text/template">
## 🙅 Anti-goals

- "Shame" under-achievement that leads to exiting the ecosystem.
  - _We want to Maximize continued high-impact involvement post academy for all students and alumni_
- Normalization for the sake of specific percent not certifying
- "Gossip" and personal gripes/bias about students leading to bias & keep (by default, without good cause) _any_ subjective details on students out of the picture _between graders_.
- Unclear and subjective points systems with no clear definition that leads to grader interpretation of what a score means
</script></section></section><section ><section data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# Assessment Framework

<aside class="notes"><p>Research for the curious in the <a href="#alternative-grading-frameworks">Alternative Grading Frameworks</a> section latter.</p>
</aside></script></section><section data-markdown><script type="text/template">
## Assessment Framework

- Competency Checklist
- Automated Grading Suite
- PR Reviews for Feedback
- Rubric and Solutions
- Scoring System
- Certification Criteria
</script></section><section data-markdown><script type="text/template">
## 🛂 Competency Checklist

Each assignment must define a set of **learning outcomes** in:

<pba-flex center>

1. Comprehension or Understanding
1. Skills or Abilities

</pba-flex>

<aside class="notes"><p>This is evaluated in a pass/fail manner, with grader feedback per item noted.</p>
<p>Some are explicitly defined to be optional-to-do items that if completed qualify for a higher level of grade.</p>
</aside></script></section><section data-markdown><script type="text/template">
## 🛂 Competency Checklist

<img rounded src="../assets/img/0-Shared/meta-slides/competency-checklist.png" />

A "report card" of an assignment, <br>concatenated into one for the _entire academy_.

<aside class="notes"><p>Competencies are for the course overall, not just the assignment - there will be overlap between assignments.</p>
</aside></script></section><section data-markdown><script type="text/template">
## 🤖 Automated Grading Framework

Based on Joshy's awesome work on the [📑 qualifying exam](https://github.com/Polkadot-Blockchain-Academy/Rust-Entrance-Exam) and [📑 assignment 0](https://github.com/Polkadot-Blockchain-Academy/pba-pre-course-assignment) we strongly suggest all (Rust based) assignments follow this standard:

<pba-flex center>

- Templated starting point with faculty to craft concrete assignments with `todo!("some things here...")` skeleton code defined
- Include "sanity check" and minimal unit tests that students _must_ complete
- Automated test suite (closed/private) to score granular pass/fail (based on learning objectives)

</pba-flex>
</script></section><section data-markdown><script type="text/template">
## 🤖 Automated Grading Framework

Fully realized test suites will:

- Push creators to craft very well defined assessments
- Externalize _most_ effort to CI job for grading
- Enable resubmission by students anytime, iterating to passing

<aside class="notes"><p>Goal is to have &quot;black box&quot; that returns only pass/fail on tests, and a score of 1, 2, or 3.</p>
</aside></script></section><section data-markdown><script type="text/template">
## 🧐 PR Reviews as Feedback

**Submissions include a README and/or PR comment**

- Points explicitly to what the SME should review
- Reflection on the work: key learning, things still to do, unresolved questions/issues the student had
</script></section><section data-markdown><script type="text/template">
## 🧐 PR Reviews as Feedback

- Github Classrooms feedback PR can be used to comment directly on the work of each student easily
- An issue (template) opened on all classroom submission repos for manual grading
  - This is then the grading rubric and/or checklist for the grader to evaluate if the PR closes the issue.
</script></section><section data-markdown><script type="text/template">
## 🧙 Rubric and Solutions

All assignments _must_ provide examples of end-to-end completed work to be included in grading, **for each possible score**

<aside class="notes"><p>For reference for faculty only for now, perhaps in a fully open course this should be open sourced.a</p>
</aside></script></section><section data-markdown><script type="text/template">
## 📊 Scoring System

**0 to 4 integer system, awarded _per assignment_**

- 0 = Nothing submitted or grossly poor performance
- 1 = Incomplete submission, under minimal requirements
- 2 = Passing all minimal requirements, pre-defined percent of test suite passing
- 3 = Passing all test suite items, including explicitly marked optional ones
- 4 = Grader discretion of going above the call of the assignment
  - Taking into account the level expected of students in context
  - Examples of what should qualify defined by creator(s)

<aside class="notes"><p>Here we use the automated grading (where possible) to arrive at a score of 0,1,2, or 3.
A 4 is only manually awarded by graders based on their review of an individual&#39;s work.</p>
</aside></script></section><section data-markdown><script type="text/template">
## ✅ Certification Criteria

**Average of integer scores for all assignments (effectively GPA)**

Future may include:
<pba-flex center>

1. Bundling of checklist items overall (above a 2)
1. Bundling of assignments total score (above a 2)
   - pre-defined
   - contract negotiated
1. Thesis Defense (only)

</pba-flex>

<aside class="notes"><p>All students can come away with a &quot;report card&quot; of all their competencies to (at their discretion) accompany their overall certification and overall score(s).
If we have many assignments we may move to bundles (4 is not enough)</p>
</aside></script></section></section><section ><section data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# Learning Resources for Faculty

_We encourage all content creators to review these!_
</script></section><section data-markdown><script type="text/template">
## [📺 Developing Quality Assessments](https://www.youtube.com/watch?v=hDjWjbng40U)

A _wonderful_ overview and workshop around various exercise and activity models that we **highly encourage everyone watch**!

- Blooms taxonomy as basis with _explicit_ terms to use when defining learning objectives and outcomes
- WHY give this assignment? in context with content
- We assess on:
  - Process (thinking through) and/or product (shipped solution {code})
  - Express ideas concisely and coherently
  - Convergent (coming to conclusion based on given) or divergent (hypothesis from predictions & unstated things)
</script></section><section data-markdown><script type="text/template">
## [📺 Best Practices for Grading<br>Objectively and Efficiently](https://www.youtube.com/watch?v=hiUXBr4sgnM)

> Note that this is for typical grading systems (out of 100, A->F) that we will _not_ employ.
</script></section><section data-markdown><script type="text/template">
## [📺 Make Grading Point-less: Eliminating Points to Foster Student Motivation](https://www.youtube.com/watch?v=CnSkOXe90WI)

Motivation around alternative grading schemes that are rigorous _and_ do not assign points.
</script></section></section><section ><section data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# Alternative Grading Frameworks

_Research for reference_
</script></section><section data-markdown><script type="text/template">
## Alternative Grading Frameworks

- Overview: [📰 UC Berkeley Alternative Grading Frameworks](https://teaching.berkeley.edu/resources/course-design-guide/design-effective-assessments/alternative-grading-frameworks)
- Also [📰 University of Miami Alternative Grading Frameworks](https://academictechnologies.it.miami.edu/explore-technologies/technology-summaries/alternative-grading/index.html)
- There are many other interesting but even less common frameworks, not discussed in this presentation.
</script></section><section data-markdown><script type="text/template">
## [📰 Grading for Equity](https://www.insidehighered.com/views/2020/01/27/advice-how-make-grading-more-equitable-opinion)

- Subjective criteria to minimum or zero
- Transparent scoring -> Are mathematically accurate to validly describe a student’s level of mastery
- No normalization
- Support hope and a growth mind-set
- “Lift the veil” on how to succeed

<aside class="notes"><ul>
<li>Transparent scoring -&gt; Are mathematically accurate to validly describe a student’s level of mastery<ul>
<li>They apply a more proportionately structured 0-4 scale instead of the 0-100 scale, which is mathematically oriented toward failure</li>
<li>They also use sound mathematical principles that reflect recent performance and growth instead of averaging performance over time</li>
</ul>
</li>
<li>Support hope and a growth mind-set<ul>
<li>They allow test/project retakes to emphasize and reward learning rather than penalize it, and they override previous scores with current scores that build learning persistence</li>
</ul>
</li>
<li>“Lift the veil” on how to succeed<ul>
<li>They create explicit descriptions of what constitutes demonstration of content mastery through rubrics or proficiency scales.</li>
<li>In addition, they simplify grade books and expand the methods of assessments to generate more accurate feedback and reporting about each student’s learning relative to the expected outcomes</li>
</ul>
</li>
</ul>
</aside></script></section><section data-markdown><script type="text/template">
## [📰 Specification Grading](https://www.insidehighered.com/views/2016/01/19/new-ways-grade-more-effectively-essay)

- Pass fail only, based on a concrete specification givin to start
- Style is very similar to issues -> PRs, **great fit for our faculty's skill set**
- Bundles of specs fulfilled to achieve various levels

<aside class="notes"><p>Here we craft what students must do to be considered passing.
This is almost a one-to-one mapping with github based workflows, and thus is not only well suited to the style of assigning and completing work that our faculty does daily, but also a bit of on-the-job-training for students.</p>
</aside></script></section><section data-markdown><script type="text/template">
## [📰 Contract Grading](https://en.wikipedia.org/wiki/Contract_grading)

- Collaboratively define grade qualifications with students (not completely pre-defined)
- Completion of a _contracted_ number of assignments of specified quality that correspond to specific letter grades
  - Instructors and students know exactly what is expected from them to receive a certain letter grade (no normalization)
  - Any student who completes the work that corresponds to a "B" grade will receive a "B" (everyone can pass)
- The grade the student receives is a reflection of how well they completed the pre-determined syllabus.

- _Variant: Labor-based contract grading = writing assessment be based on effort rather than on a subjective evaluation_
</script></section><section data-markdown><script type="text/template">
## [📰 Ungrading](https://www.insidehighered.com/advice/2017/11/14/significant-learning-benefits-getting-rid-grades-essay)

- Clear instructions, although not necessarily criteria or contracts, for students to follow
- Flexibility with assignment deadlines and provide opportunities for revision
- Open conversations about performance (bi-weekly conferences, feedback surveys, or asking outright what grade they deserve)
  - Self-assessment drives the grade, not nearly as much a grader.

<aside class="notes"><p>Reflection and Dialogue are key: Ungrading builds upon similar aspects of specifications and contract grading
Ungrading does encourage instructors to have more open conversations with students about their performance, whether it is through bi-weekly conferences, feedback surveys, or asking students outright what grade to put in the system at the end of the term (Blum &amp; Kohn, 2020)
These conversations in addition to other self-reflective exercises (i.e. minute tickets, process letters, peer feedback, etc.) require students to think critically about what they’ve learned and articulate how they have developed their knowledge and skills throughout the semester</p>
</aside></script></section><section data-markdown><script type="text/template">
## [Competency Grading 📺](https://www.youtube.com/watch?v=YQInjf8UjOo)

Great explainer in [three](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading) - [part](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading-2) - [series](https://www.nciea.org/blog/what-do-i-need-to-know-about-competency-based-grading-3)

**This is the basis for assessments we will mostly embrace**

<aside class="notes"><p>More concrete implementation in the <a href="#assessment-framework">Assessment Framework</a> section.</p>
</aside></script></section></section><section ><section data-markdown><script type="text/template">
<!-- .slide: data-background-color="#4A2439" -->

# PBA Thesis Driven Certifications

_For now, just and idea to discuss_
</script></section><section data-markdown><script type="text/template">
## Thesis Model Motivation

- Students can dig deep into passions, with structure and support to arrive at some tangible result from it
- Ability _subjectively_ assess students' novel work could be PBA's SMEs _unique_ value proposition
- Removes time constraint of cohort closing ceremonies
- _Con: new, extra time, different work scope required from faculty_

<aside class="notes"><p>Especially if course content is much more open, we need things that make the PBA long term value adding over maintaining and running content.</p>
</aside></script></section><section data-markdown><script type="text/template">
## Thesis Driven Certification Integration

- Certifications based on scoring system remain, with option for _participation only_ if student opts-out of graded work to focus on thesis during the academy
  - Similar in concept to Founders Track (ungraded)
- Post-cohort successful thesis defense lead to specific "proper" certifications/degrees (engineering, founder, etc.)

<aside class="notes"><p>The cert. exception may be the Application Engineers (parachain and solochain engineering) for completion of some level in all assignments.</p>
</aside></script></section><section data-markdown><script type="text/template">
## Thesis Driven Certification Flow

Successful completion of a PBA cohort is akin to a "mini-masters" program, the thesis track kickoff during, and continue _post cohort_:

<pba-flex center>

1. Commit to Thesis Advisor (During or shortly after PBA)
   - Student & advisor mutually agree on relationship
1. Thesis Proposal: defines work to be done,<br>approved by Advisor (and retries as needed)
   - Modeled like W3F grant (if not actually one)
1. Thesis work: async support from Advisor and PBA
1. Thesis Committee: SMEs to evaluate thesis
1. Thesis Defense
1. Certification Awarded

</pba-flex>

<aside class="notes"><p>This is somewhat akin to a on-the-job training program or internship before a student is hired within our ecosystem.
It is a fantastic chance to help build a relationship with the committee and showcase your ability in a formalized way that is not possible presently (AFAIK).</p>
</aside></script></section></section>
    </article>
  </main>

  <script src="./../dist/reveal.js"></script>

  <script src="./../plugin/markdown/markdown.js"></script>
  <script src="./../plugin/highlight/highlight.js"></script>
  <script src="./../plugin/zoom/zoom.js"></script>
  <script src="./../plugin/notes/notes.js"></script>
  <script src="./../plugin/math/math.js"></script>

  <script src="./../assets/plugin/mermaid.js"></script>
  <script src="./../assets/plugin/mermaid-theme.js"></script>

  <script src="./../assets/plugin/chart/chart.js"></script>
  <script src="./../assets/plugin/chart/chart.min.js"></script>

  <script src="./../assets/plugin/tailwindcss.min.js"></script>

  <script>
    function extend() {
      var target = {};
      for (var i = 0; i < arguments.length; i++) {
        var source = arguments[i];
        for (var key in source) {
          if (source.hasOwnProperty(key)) {
            target[key] = source[key];
          }
        }
      }
      return target;
    }

    // default options to init reveal.js
    var defaultOptions = {
      controls: true,
      progress: true,
      history: true,
      center: true,
      transition: 'default', // none/fade/slide/convex/concave/zoom
      slideNumber: true,
      mermaid: {
        startOnLoad: false,
        logLevel: 3,
        theme: 'base',
        themeVariables: {
          primaryColor: purple,
          primaryTextColor: white,
          primaryBorderColor: pink,
          lineColor: pink,
          secondaryColor: lightPurple,
          tertiaryColor: lightPurple,
        },
      },
      chart: {
        defaults: {
          color: 'lightgray', // color of labels
          scale: {
            beginAtZero: true,
            ticks: { stepSize: 1 },
            grid: { color: "lightgray" }, // color of grid lines
          },
        },
        line: { borderColor: ["#ccc", "#E6007A", "#6D3AEE"], "borderDash": [[5, 10], [0, 0]] },
        bar: { backgroundColor: ["#ccc", "#E6007A", "#6D3AEE"] },
      },
      plugins: [
        RevealMarkdown,
        RevealHighlight,
        RevealZoom,
        RevealNotes,
        RevealMath,
        RevealMermaid,
        RevealChart
      ]
    };

    // options from URL query string
    var queryOptions = Reveal().getQueryHash() || {};

    var options = extend(defaultOptions, {"width":1400,"height":900,"margin":0,"minScale":0.2,"maxScale":2,"transition":"none","controls":true,"progress":true,"center":true,"slideNumber":true,"backgroundTransition":"fade"}, queryOptions);
  </script>


  <script>
    Reveal.initialize(options);
  </script>
</body>

</html>